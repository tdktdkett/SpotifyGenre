---
title: "FinalProject"
author: "Dikai Tang"
date: "11/5/2019"
output: html_document
---

### 0, misc
```{R}
library(DT)
library(rvest)
library(data.table)
library(tidyverse)
library(ggplot2)
library(caret)
library(mda)
library(VGAM)
library(kernlab)
library(randomForest)
library(tree)
suppressMessages(library(leaps))
set.seed(1)
```

### 1. Score Functions, D
``` {R} 
modelScore <- function(result, ref){ #result n x 3, ref n x 1
  generalScore <- 0
  for(i in 1:nrow(ref)) {
    if (result[i,1] == ref[i,]){
      score <- 100
    } else if (result[i,2] == ref[i,]) {
      score <- 100
    }else if (result[i,3] == ref[i,]) {
      score <- 100
    }else {
      score <- 0
    }
    generalScore = generalScore + score
  }
  generalScore = generalScore / nrow(ref)
}
```

## 2. Data Cleaning, 
```{R warning = F,message= F}
setwd("D:/onedrive/private/Study/CalPoly/courses/GSB524MachineLearning/assignments/FinalProject/")
data <- data.frame(read_csv("SpotifyFeatures.csv"))
colnames(data)
# 1.1 most popular
mostPopularByArtist <- data #%>% group_by(artist_name) %>% top_n(1, popularity) %>% data.frame() 
#mostPopularByArtist <- mostPopularByArtist[mostPopularByArtist$popularity > 30, ]
# 1.2 exclude a few 
mostPopularByArtist <- mostPopularByArtist[!grepl("World|Child|Anime|Soundtrack|Movie|Comedy", mostPopularByArtist$genre),]
# 1.3 merge rap & hip-hop
mostPopularByArtist$genre[mostPopularByArtist$genre == "Hip-Hop"] <- "Rap"
mostPopularByArtist$genre[mostPopularByArtist$genre == "Reggaeton"] <- "Reggae"
data2<-mostPopularByArtist %>%
  select(-c(track_id, time_signature, track_name, artist_name, mode, key, popularity))

```

## 3. Explore Plot
Plotting the distributions of a few features by genre. 
```{R}

ggplot(mostPopularByArtist, aes(x=loudness, colour=genre)) + geom_density()
ggplot(mostPopularByArtist, aes(x=energy, colour=genre)) + geom_density()
ggplot(mostPopularByArtist, aes(x=tempo, colour=genre)) + geom_density()
ggplot(mostPopularByArtist, aes(x=speechiness, colour=genre)) + geom_density()
ggplot(mostPopularByArtist, aes(x=log(instrumentalness), colour=genre)) + geom_density()
ggplot(mostPopularByArtist, aes(x=acousticness, colour=genre)) + geom_density()
ggplot(mostPopularByArtist, aes(x=loudness, colour=genre)) + geom_density()
#ggplot(mostPopularByArtist[mostPopularByArtist$genre %in% c("Pop","Movie","Classical"),], aes(x=loudness, colour=genre)) + geom_density()

```

```{r}
library(MASS)
library(class)
```

Subset the data for a sample of 5000
```{r}
sample_data <- data2[sample(1:nrow(data2), 10000, replace=FALSE),]
sample_data<-na.omit(sample_data)
sample_data$genre<-factor(sample_data$genre)
```

Split the data into testing and training sets
```{r}
set.seed(1)

## 75% of the sample size
smp_size <- floor(0.75 * nrow(sample_data))

train_ind <- sample(seq_len(nrow(sample_data)), size = smp_size)
train <- sample_data[train_ind, ]
test <- sample_data[-train_ind, ]
```



### 4.1 Random Forest Classifier 
```{r}
sd.rf<-randomForest(genre~., data=train, mtry=10, importance=TRUE)
importance(sd.rf, type = 1)
```
Based on the Random Forest Classifier, we see that the variables that stand out as being the most important for classification accurate are speechiness, instrumentalness, danceability, and acousticness.

```{r}
sd.rf
```

```{r}
rf_pred<-predict(sd.rf, newdata = test)
plot(rf_pred, test$genre)
```
```{r}
mean(rf_pred==test$genre)*100
```
```{r}
rf_error<-list()
ntrees<-list()
rf_models<-list()

for (i in 1:10) {
  ntrees[[i]]<-i
  rf_models[[i]]<-sd.rf<-randomForest(genre~., data=train, mtry=10, ntree=i, importance=TRUE)
  rf_pred<-predict(rf_models[[i]], newdata = test)
  rf_error[[i]]<-mean(rf_pred==test$genre)*100
}
```

```{r}
plot(ntrees, rf_error)
```


# Decision Tree
```{r}
genre_tree<-tree(genre~speechiness+instrumentalness+danceability+acousticness, data=train)

summary(genre_tree)
```
```{r}
tree_pred<-predict(genre_tree, test, type="class")
table(tree_pred, test$genre)

mean(tree_pred == test$genre)
```
```{r}
cv_genre<-cv.tree(genre_tree, FUN=prune.misclass)
names(cv_genre)
cv_genre
```
```{r}
#par(mfrow<=c(1,2))
plot(cv_genre$size, cv_genre$dev, type="b")
plot(cv_genre$k, cv_genre$dev, type="b")
```
```{r}
prune_genre<-prune.misclass(genre_tree, best=105)
plot(prune_genre)
text(prune_genre, pretty=0)
```
```{r}
genre_pred<-predict(prune_genre, test, type="class")
#table(genre_pred, test$genre)

mean(genre_pred == test$genre)
```


#LDA
```{r}
lda_model <- lda(genre ~ acousticness+danceability+speechiness+instrumentalness, data = train)
```

```{r}
pred_lda <- predict(lda_model, test, type="response")

mean(pred_lda$class != test$genre)
```


## 5. kNN, M
```{r}
train_X2 = cbind(train$acousticness, train$danceability, train$speechiness, train$instrumentalness)

test_X2 = cbind(test$acousticness, test$danceability, test$speechiness, test$instrumentalness)
train_Y2 = cbind(train$genre)
```

```{r}
knn_error<-list()
k_values<-list()
knn_models<-list()

for (i in 1:100) {
  k_values[[i]]<-i
  knn_models[[i]]<-knn(train_X2, test_X2, train_Y2, k=i)
  tab<-table(knn_models[[i]], test$genre)
  knn_error[[i]]<-round((sum(tab[1,2], tab[2,1])/dim(test)[1])*100, 10)
}

plot(k_values, knn_error, type="b")
```


## 7. New Model KSVM, M 
### 7.1 Variable selection for KSVM
```{R}
#Maybe remove a few features more 
trainVar <- c("genre","acousticness",
               "danceability","duration_ms","energy",
               "instrumentalness","liveness",
               "loudness","speechiness",
               "tempo","valence")
trainSample <- mostPopularByArtist[sample(1:nrow(mostPopularByArtist), 20000, replace=FALSE),]
tstSample <- mostPopularByArtist[sample(1:nrow(mostPopularByArtist), 1000, replace=FALSE), ]
```
### 7.2 KSVM algorithms
```{R}
# fit model
fit <- ksvm(genre ~ ., data = trainSample[,trainVar])
# geting the votes of genres for a specific song 
vote <- predict(fit, tstSample[,trainVar], type="votes")
# converting votes into predictKSVM, result table to be combined 
predictKSVM <- data.table()
# genres' Names to be used
genreNames <- lev(fit)
# for each song, selecting most voted 3 genre as predicteKSVM
for(i in 1:nrow(tstSample)){
  topVotes<- sort(vote[,i], index.return=TRUE, decreasing=TRUE)$ix[1:3]
  topGenre<- genreNames[topVotes]
  predictKSVM<- rbind(predictKSVM, t(topGenre), fill=TRUE) 
}
# Changes name of columns
colnames(predictKSVM)[1:3] <- c("Genre A", "Genre B", "Genre C")
# Merge result with test sample
resultKSVM <- cbind(predictKSVM, tstSample)
# Calulate the score of model.
scoreKSVM <- modelScore(predictKSVM, data.table(tstSample[,1]))
scoreKSVM
```
The score was generate as percentage of top 3 predicted Genre include the actual genre. The overall accurate rate is around 60%.
### 7.3 Ploting of result
Plotting the confusion matrix by its' most distinct prediction(Genre 1) vs Actual. Some of the genres were easy to be predicted, like classic, Rap, and electronic because of some distinct features. While genres like pop doesn't have a clear definition of the music as they were usually a combinition of popular singers. 
```{R}
prettyConfused<-function(Actual,Predict,colors=c("white","red4","dodgerblue3"),text.scl=5){
  actual = as.data.frame(table(Actual))
  names(actual) = c("Actual","ActualFreq")

  #build confusion matrix
  confusion = as.data.frame(table(Actual, Predict))
  names(confusion) = c("Actual","Predicted","Freq")

  #calculate percentage of test cases based on actual frequency

  confusion = merge(confusion, actual, by=c('Actual','Actual'))
  confusion$Percent = confusion$Freq/confusion$ActualFreq*100
  confusion$ColorScale<-confusion$Percent*-1
  confusion[which(confusion$Actual==confusion$Predicted),]$ColorScale<-confusion[which(confusion$Actual==confusion$Predicted),]$ColorScale*-1
  confusion$Label<-paste(round(confusion$Percent,0),"%, n=",confusion$Freq,sep="")
  tile <- ggplot() +
    geom_tile(aes(x=Actual, y=Predicted, fill=ColorScale),data=confusion, color="black",size=0.1) +
    labs(x="Actual",y="Predicted") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  tile = tile +
        geom_text(aes(x=Actual,y=Predicted, label=Label),data=confusion, size=text.scl, colour="black") +
        scale_fill_gradient2(low=colors[2],high=colors[3],mid=colors[1],midpoint = 0,guide='none')
}

confusionMatrix(as.factor(t(resultKSVM[,1])),as.factor(t(resultKSVM[,4])))
actual <- as.factor(t(resultKSVM[,4]))
predicted <- as.factor(t(resultKSVM[,1]))
predicted <- factor(predicted, levels=levels(actual))
mtx <- prettyConfused(Actual = actual, Predict = predicted, text.scl=1)
mtx
```


## 8 Summary
### 8.1 General
With this dataset of limited features, some of the genres could be roughly predicted, while other can't. Usually definitions of music genres are blurr and objective, genres for a song is not sigular and unique. sometimes the second and third order prediction matches genre in the dataset. 
The features might not be good enough for a detailed and accurate genre predicting, Difference between a Rap and R&B varies by generation, supplimental details from the song itself maybe lyrics plays a role in a classification process by people. 
### 8.n existing problems
1. The "Actual" Genres were tags scraped from the artist, while a artist produces a varity kinds of songs, the genre tags does not necessarily reflect the real feature of a specific song. So the train samples itself was biased. 

